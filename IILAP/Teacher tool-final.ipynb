{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "817791b9-8b61-4f98-b6fc-3faf0275abd5",
   "metadata": {},
   "source": [
    "# Teacher tool "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee833d9-63f5-4e64-ac33-d2bfdfdfa69a",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fcc43b6-82b4-4876-9760-7ec1456824ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f07fe222-4732-4bb4-a3cf-74fe0d54e87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9363091f-b12a-4877-b813-30dde2d4957d",
   "metadata": {},
   "source": [
    "## Load and Save Dataset Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c6517b9-2664-4373-b9f1-e5616620897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"data_annotation_new_2.csv\"\n",
    "credibility_file = \"source_credibility_2.json\"\n",
    "dataset = []\n",
    "source_credibility = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72155d24-d1c4-43ae-94aa-02f055b6b9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    global dataset\n",
    "    if os.path.isfile(csv_file):\n",
    "        try:\n",
    "            df = pd.read_csv(csv_file, encoding=\"utf-8\")\n",
    "        except UnicodeDecodeError:\n",
    "            try:\n",
    "                df = pd.read_csv(csv_file, encoding=\"utf-8-sig\")\n",
    "            except UnicodeDecodeError:\n",
    "                df = pd.read_csv(csv_file, encoding=\"ISO-8859-1\")\n",
    "        dataset[:] = df.to_dict(orient=\"records\")\n",
    "    else:\n",
    "        dataset = []\n",
    "\n",
    "def save_dataset():\n",
    "    df = pd.DataFrame(dataset)\n",
    "    df.to_csv(csv_file, index=False, quoting=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b836c27-e9b2-4daf-9180-129963fd09e1",
   "metadata": {},
   "source": [
    "## Source Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d914ec43-5085-4b9b-afd0-abdbd276ed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_credibility():\n",
    "    global source_credibility\n",
    "    if os.path.isfile(credibility_file):\n",
    "        with open(credibility_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            source_credibility = json.load(f)\n",
    "    else:\n",
    "        source_credibility = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2ed5d24-030b-467a-9db3-608053a4ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_credibility():\n",
    "    with open(credibility_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(source_credibility, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3369095f-5036-460a-8e55-44529df9e36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_credibility_table():\n",
    "    df = pd.DataFrame(list(source_credibility.items()), columns=[\"Source\", \"Credibility\"])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f349ab4-d0ca-442c-b296-0a55d180bde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_or_update_source(name, level):\n",
    "    if level not in [\"Low\", \"Medium\", \"High\"]:\n",
    "        return \"\\u26a0\\ufe0f Credibility must be 'Low', 'Medium', or 'High'\", get_credibility_table()\n",
    "    source_credibility[name.strip()] = level\n",
    "    save_credibility()\n",
    "    return f\"‚úÖ Source '{name}' added/updated.\", get_credibility_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5dee8b4-26e2-4a46-999b-fca0d0e16f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_source(name):\n",
    "    name = name.strip()\n",
    "    if name in source_credibility:\n",
    "        del source_credibility[name]\n",
    "        save_credibility()\n",
    "        return f\"üóëÔ∏è Source '{name}' deleted.\", get_credibility_table()\n",
    "    return \"\\u26a0\\ufe0f Source not found.\", get_credibility_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d791b25c-ab55-4b77-94dd-ab6dab191eca",
   "metadata": {},
   "source": [
    "## Data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f86282f0-9c10-4c6f-9a73-3adef815e30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_simple_annotations(q, a, true_parts, true_sources, true_names, false_parts, false_sources, false_names, issues):\n",
    "    true_parts_list = [p.strip() for p in true_parts.strip().splitlines() if p.strip()]\n",
    "    true_sources_list = [s.strip() for s in true_sources.strip().splitlines() if s.strip()]\n",
    "    true_names_list = [n.strip() for n in true_names.strip().splitlines() if n.strip()]\n",
    "    false_parts_list = [p.strip() for p in false_parts.strip().splitlines() if p.strip()]\n",
    "    false_sources_list = [s.strip() for s in false_sources.strip().splitlines() if s.strip()]\n",
    "    false_names_list = [n.strip() for n in false_names.strip().splitlines() if n.strip()]\n",
    "\n",
    "    entry = {\n",
    "        \"question\": q.strip(),\n",
    "        \"answer\": a.strip(),\n",
    "        \"confirmed_parts\": json.dumps(true_parts_list, ensure_ascii=False),\n",
    "        \"confirmed_sources\": json.dumps(true_sources_list, ensure_ascii=False),\n",
    "        \"false_claim_parts\": json.dumps(false_parts_list, ensure_ascii=False),\n",
    "        \"false_claim_sources\": json.dumps(false_sources_list, ensure_ascii=False),\n",
    "        \"confirmed_sources_names\": json.dumps(true_names_list, ensure_ascii=False),\n",
    "        \"fake_sources_names\": json.dumps(false_names_list, ensure_ascii=False),\n",
    "        \"annotation_issues\": json.dumps(issues, ensure_ascii=False),\n",
    "    }\n",
    "\n",
    "    dataset.append(entry)\n",
    "    save_dataset()\n",
    "    df = pd.DataFrame(dataset)\n",
    "    return \"‚úÖ Entry saved!\", df.to_csv(index=False, quoting=1), df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4c106c7-4fa8-4951-8b51-2c0950a79e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_row(index):\n",
    "    index = int(index)\n",
    "    if 0 <= index < len(dataset):\n",
    "        del dataset[index]\n",
    "        save_dataset()\n",
    "        df = pd.DataFrame(dataset).reset_index().rename(columns={\"index\": \"Row Index\"})\n",
    "        return f\"üóëÔ∏è Deleted row {index + 1}\", df.to_csv(index=False, quoting=1), df\n",
    "    else:\n",
    "        df = pd.DataFrame(dataset).reset_index().rename(columns={\"index\": \"Row Index\"})\n",
    "        return \"\\u26a0\\ufe0f Invalid index\", df.to_csv(index=False, quoting=1), df\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82324555-c032-4878-9d5a-866489b3309b",
   "metadata": {},
   "source": [
    "## Launching the student interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1b71f17-99c9-470f-8b3b-6a84ce09be54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_student_interface():\n",
    "    proc = subprocess.Popen([sys.executable, \"-u\", \"student_interface.py\"], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, bufsize=1)\n",
    "    public_url = None\n",
    "    while True:\n",
    "        line = proc.stdout.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        decoded_line = line.decode(\"utf-8\").strip()\n",
    "        match = re.search(r'(https?://\\S*gradio\\.live\\S*)', decoded_line)\n",
    "        if match:\n",
    "            public_url = match.group(1)\n",
    "            break\n",
    "    if public_url:\n",
    "        return f'''\n",
    "            <div>\n",
    "                <a href=\"{public_url}\" target=\"_blank\" style=\"font-size:16px; font-weight:bold; color:#007bff;\">Click to continue</a>\n",
    "                <br><br>\n",
    "                <input type=\"text\" value=\"{public_url}\" style=\"width:100%; font-size:14px; padding:8px;\" readonly onclick=\"this.select(); document.execCommand('copy');\" />\n",
    "                <small style=\"color:gray;\">(Click the link above or copy this URL)</small>\n",
    "            </div>\n",
    "        '''\n",
    "    else:\n",
    "        return \"Failed to capture student interface URL.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb38c49-0395-46ed-bc21-b8fc38d13948",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59b8a621-dec5-4d7d-8358-2dbf765b8ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_evaluation(c1, c2, c3, c4, c5,c6):\n",
    "    coefs = [c1, c2, c3, c4, c5,c6]\n",
    "\n",
    "    # Check if all inputs are floats and >= 0\n",
    "    try:\n",
    "        coefs = [float(c) for c in coefs]\n",
    "    except Exception:\n",
    "        return \"‚ö†Ô∏è Please enter valid decimal numbers for all coefficients.\", \"\"\n",
    "\n",
    "    if any(c < 0 for c in coefs):\n",
    "        return \"‚ö†Ô∏è Coefficients must be non-negative.\", \"\"\n",
    "\n",
    "    total = sum(coefs)\n",
    "    if abs(total - 100.0) > 1e-6:\n",
    "        return f\"‚ö†Ô∏è The total of coefficients must be exactly 100%. Currently: {total}%.\", \"\"\n",
    "\n",
    "    eval_df = pd.DataFrame({\n",
    "        \"coef1\": [coefs[0]],\n",
    "        \"coef2\": [coefs[1]],\n",
    "        \"coef3\": [coefs[2]],\n",
    "        \"coef4\": [coefs[3]],\n",
    "        \"coef5\": [coefs[4]],\n",
    "        \"coef6\": [coefs[5]],\n",
    "    })\n",
    "    eval_csv_path = \"evaluation_input.csv\"\n",
    "    eval_df.to_csv(eval_csv_path, index=False)\n",
    "\n",
    "    try:\n",
    "        proc = subprocess.run([sys.executable, \"evaluation.py\"], capture_output=True, text=True, timeout=30)\n",
    "        output = proc.stdout\n",
    "        err = proc.stderr\n",
    "        if err:\n",
    "            output += \"\\n[Error output]\\n\" + err\n",
    "    except Exception as e:\n",
    "        return f\"‚ö†Ô∏è Failed to run evaluation.py: {e}\", \"\"\n",
    "\n",
    "    return \"‚úÖ Evaluation completed.\", output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671e0c71-b6f8-48ab-bf54-0c05874d158a",
   "metadata": {},
   "source": [
    "## Interface functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4255292b-56b5-4d00-8c5b-5894253e702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dataset()\n",
    "load_credibility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baf339d7-532a-49cc-aeee-f7808776adf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7892\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7892/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks(theme=gr.themes.Soft(), css=\"textarea { font-size: 15px !important }\") as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "<h1 style=\"text-align: center;\">üìö Simulated Chat Bot Teacher Tool</h1>\n",
    "<p style=\"text-align: center; font-size: 16px;\">\n",
    "Manage chatbot data, verify annotations, assess source credibility, deploy a student-facing interface, and run evaluations‚Äîall in one place.\n",
    "</p>\n",
    "<hr>\n",
    "\"\"\")\n",
    "\n",
    "    with gr.Row():\n",
    "        show_add = gr.Button(\"‚úçÔ∏è Add New Annotation\")\n",
    "        show_data = gr.Button(\"üìã Existing Data\")\n",
    "        show_cred = gr.Button(\"üìä Source Credibility\")\n",
    "        show_student = gr.Button(\"üöÄ Launch Student Interface\")\n",
    "        show_eval = gr.Button(\"üßÆ Evaluation\")  # New button\n",
    "\n",
    "\n",
    "    with gr.Column(visible=True) as add_block:\n",
    "        with gr.Group():\n",
    "            with gr.Row():\n",
    "                question = gr.Textbox(label=\"üß† Question\", lines=2)\n",
    "                answer = gr.Textbox(label=\"üìÑ Full Answer\", lines=4)\n",
    "\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    gr.Markdown(\"### ‚úÖ  Sentence(s) to be highlighted green\")\n",
    "                    true_parts = gr.Textbox(label=\"‚úîÔ∏è Sentences\", lines=2)\n",
    "                    true_sources = gr.Textbox(label=\"üîó Source URLs\", lines=2)\n",
    "                    true_names = gr.Textbox(label=\"üìö Source Names\", lines=2)\n",
    "                with gr.Column():\n",
    "                    gr.Markdown(\"### ‚ùå Sentence(s) to be highlighted red \")\n",
    "                    false_parts = gr.Textbox(label=\"‚ùå  Sentences\", lines=2)\n",
    "                    false_sources = gr.Textbox(label=\"üîó  Source URLs\", lines=2)\n",
    "                    false_names = gr.Textbox(label=\"üìï  Source Names\", lines=2)\n",
    "\n",
    "            \n",
    "\n",
    "            issue_options = [\n",
    "                \"Text is not highlighted\", \"True data labeled as true\", \"False data labeled as false\",\n",
    "                \"Source link missmatch\", \"Good source linking\", \"False data appears in unhighlighted text\",\n",
    "                \"Source appears but is not highlighted in text\", \"True data labeled as false\", \"False data labeled as true\", \"Wrong source credibility score\",\"Correct source credibility score\"\n",
    "            ]\n",
    "            issues = gr.CheckboxGroup(label=\"‚ö†\\ufe0f Row categories\", choices=issue_options)\n",
    "\n",
    "            save_btn = gr.Button(\"üìè Save Row\")\n",
    "            status = gr.Textbox(label=\"üìù Status\", interactive=False)\n",
    "\n",
    "    with gr.Column(visible=False) as data_block:\n",
    "        csv_output = gr.Textbox(label=\"üìÑ CSV Preview\", lines=10, interactive=False, visible=False)\n",
    "        with gr.Row():\n",
    "            delete_index = gr.Number(label=\"üóëÔ∏è Row Index to Delete\", value=0, precision=0)\n",
    "            delete_btn = gr.Button(\"üóëÔ∏è Delete Row\")\n",
    "        table = gr.Dataframe(label=\"üóæ Current Dataset\", interactive=False, wrap=True)\n",
    "\n",
    "    with gr.Column(visible=False) as student_block:\n",
    "        launch_btn = gr.Button(\"Launch Student Interface\")\n",
    "        student_output = gr.HTML()\n",
    "    with gr.Column(visible=False) as eval_block:\n",
    "        gr.Markdown(\"### Adjust Score Coefficients (%of total score)\")\n",
    "        with gr.Row():\n",
    "            coef1 = gr.Number(label=\"Number of clicks 1+ \", value=20, precision=2)\n",
    "            coef2 = gr.Number(label=\"Total number of questions 8+ \", value=20, precision=2)\n",
    "            coef3 = gr.Number(label=\"More than 10 s spent on source \", value=20, precision=2)\n",
    "            coef4 = gr.Number(label=\"More than 20s between questions \", value=20, precision=2)\n",
    "            coef5 = gr.Number(label=\"Quiz score\", value=10, precision=2)\n",
    "            coef6 = gr.Number(label=\"Correctly identified errors \", value=10, precision=2)\n",
    "        run_eval_btn = gr.Button(\"‚ñ∂Ô∏è Run Evaluation\")\n",
    "        eval_status = gr.Textbox(label=\"Evaluation Status\", interactive=False)\n",
    "        eval_output = gr.Textbox(label=\"Evaluation Output\", lines=3, interactive=False)\n",
    "\n",
    "    with gr.Column(visible=False) as credibility_block:\n",
    "        gr.Markdown(\n",
    "    \"### üîç Manage Source Credibility\\n\\n\"\n",
    "    \"Preview all sources from the dataset. Add, update, or remove sources and their credibility levels here. \"\n",
    "    \"(All sources not in this list will be labeled as having unknown credibility.)\"\n",
    ")\n",
    "        with gr.Row():\n",
    "            source_name = gr.Textbox(label=\"üî† Source Name\")\n",
    "            credibility_level = gr.Dropdown([\"Low\", \"Medium\", \"High\"], label=\"üéØ Credibility Level\")\n",
    "\n",
    "        with gr.Row():\n",
    "            add_update_btn = gr.Button(\"‚ûï Add / Update\")\n",
    "            delete_source_btn = gr.Button(\"‚ùå Delete\")\n",
    "\n",
    "        cred_status = gr.Textbox(label=\"üìù Status\", interactive=False)\n",
    "        credibility_table = gr.Dataframe(label=\"üìã Credibility List\", interactive=False, wrap=True)\n",
    "\n",
    "    def toggle_section(name):\n",
    "        return (\n",
    "        gr.update(visible=(name == \"add\")),\n",
    "        gr.update(visible=(name == \"data\")),\n",
    "        gr.update(visible=(name == \"cred\")),\n",
    "        gr.update(visible=(name == \"student\")),\n",
    "        gr.update(visible=(name == \"eval\")),\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    show_add.click(fn=lambda: toggle_section(\"add\"), inputs=[], outputs=[add_block, data_block, credibility_block, student_block, eval_block])\n",
    "    show_data.click(fn=lambda: toggle_section(\"data\"), inputs=[], outputs=[add_block, data_block, credibility_block, student_block, eval_block])\n",
    "    show_cred.click(fn=lambda: toggle_section(\"cred\"), inputs=[], outputs=[add_block, data_block, credibility_block, student_block, eval_block])\n",
    "    show_student.click(fn=lambda: toggle_section(\"student\"), inputs=[], outputs=[add_block, data_block, credibility_block, student_block, eval_block])\n",
    "    show_eval.click(fn=lambda: toggle_section(\"eval\"), inputs=[], outputs=[add_block, data_block, credibility_block, student_block, eval_block])\n",
    " \n",
    "    save_btn.click(save_simple_annotations,\n",
    "        inputs=[question, answer, true_parts, true_sources, true_names, false_parts, false_sources, false_names, issues],\n",
    "        outputs=[status, csv_output, table])\n",
    "\n",
    "    delete_btn.click(delete_row, inputs=[delete_index], outputs=[status, csv_output, table])\n",
    "    launch_btn.click(fn=launch_student_interface, inputs=[], outputs=[student_output])\n",
    "\n",
    "    add_update_btn.click(fn=add_or_update_source,\n",
    "                         inputs=[source_name, credibility_level],\n",
    "                         outputs=[cred_status, credibility_table])\n",
    "\n",
    "    delete_source_btn.click(fn=delete_source,\n",
    "                            inputs=[source_name],\n",
    "                            outputs=[cred_status, credibility_table])\n",
    "    run_eval_btn.click(run_evaluation,inputs=[coef1, coef2, coef3, coef4, coef5,coef6],outputs=[eval_status, eval_output])\n",
    "\n",
    "\n",
    "    demo.load(    lambda: (        \"\",         pd.DataFrame(dataset).reset_index().to_csv(index=False, quoting=1), \n",
    "        pd.DataFrame(dataset).reset_index().rename(columns={\"index\": \"Row Index\"}),         get_credibility_table()    ),    inputs=[], \n",
    "    outputs=[status, csv_output, table, credibility_table]        )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(server_name=\"0.0.0.0\", server_port=7892)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22afd14f-a407-47b4-a5d1-ebd95f47786f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python python_3.10 llm_interface",
   "language": "python",
   "name": "llm_interface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
